# DLBasic Module

The DLBasic module provides fundamental tensor operations commonly used in deep learning.

## Features

### Mathematical Operations
- TensorAdd: Element-wise addition of tensors
- TensorSubtract: Element-wise subtraction of tensors
- TensorMultiply: Element-wise multiplication of tensors
- TensorDivide: Element-wise division of tensors
- TensorPower: Raise tensor elements to specified powers
- TensorSqrt: Compute square root of tensor elements
- TensorTranspose: Transpose tensors
- TensorReshape: Reshape tensors to different dimensions

### Reduction Operations
- TensorSum: Compute sum of tensor elements
- TensorMean: Compute mean of tensor elements
- TensorMax: Find maximum values in tensors
- TensorMin: Find minimum values in tensors

### Activation Functions
- TensorReLU: Apply Rectified Linear Unit activation
- TensorLeakyReLU: Apply Leaky ReLU activation
- TensorSigmoid: Apply Sigmoid activation
- TensorTanh: Apply Hyperbolic Tangent activation
- TensorSoftmax: Apply Softmax activation
- TensorELU: Apply Exponential Linear Unit activation

### Tensor Manipulation
- TensorSqueeze: Remove dimensions of size 1
- TensorUnsqueeze: Add dimensions of size 1
- TensorConcatenate: Concatenate tensors along specified dimensions
- TensorAbs: Compute absolute values of tensor elements
- TensorSin: Compute sine of tensor elements
- TensorCos: Compute cosine of tensor elements
- TensorExp: Compute exponential of tensor elements
- TensorLog: Compute natural logarithm of tensor elements

## Example Workflow

See `example_workflow.json` in the DLBasic directory for a demonstration of how to use these nodes.