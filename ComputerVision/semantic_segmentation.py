import torch
import torch.nn.functional as F
import numpy as np
from typing import Tuple, Dict, Any, List

class SemanticSegmentationNode:
    """
    è¯­ä¹‰åˆ†å‰²èŠ‚ç‚¹
    
    å¯¹è¾“å…¥å›¾åƒæ‰§è¡Œè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ã€‚æ”¯æŒå¤šç§åŸºç¡€æ¨¡å‹æ¶æ„ï¼Œ
    å¯ç”¨äºCIFAR-10æˆ–ImageNet Dogsç­‰ä»»åŠ¡çš„åƒç´ çº§åˆ†ç±»ã€‚
    """
    
    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Dict[str, Any]]:
        return {
            "required": {
                "image_batch": ("IMAGE",),
                "segmentation_model": ([
                    "fcn_resnet50", 
                    "fcn_resnet101", 
                    "deeplabv3_resnet50", 
                    "deeplabv3_resnet101",
                    "unet"
                ], {"default": "fcn_resnet50"}),
                "num_classes": ("INT", {"default": 10, "min": 2, "max": 1000, "step": 1}),
                "output_size": ("INT", {"default": 224, "min": 32, "max": 1024, "step": 32})
            },
            "optional": {
                "pretrained": ("BOOLEAN", {"default": True}),
                "background_class": ("BOOLEAN", {"default": True}),
                "confidence_threshold": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01})
            }
        }

    RETURN_TYPES = ("MASK", "IMAGE", "TENSOR")
    RETURN_NAMES = ("segmentation_masks", "overlay_image", "class_probabilities")
    FUNCTION = "segment"
    CATEGORY = "ComfyNN/DeepLearning/ComputerVision"

    def segment(
        self, 
        image_batch: torch.Tensor,
        segmentation_model: str,
        num_classes: int,
        output_size: int,
        pretrained: bool = True,
        background_class: bool = True,
        confidence_threshold: float = 0.5
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        æ‰§è¡Œè¯­ä¹‰åˆ†å‰²
        
        Args:
            image_batch: è¾“å…¥å›¾åƒæ‰¹æ¬¡ [B, H, W, C]
            segmentation_model: åˆ†å‰²æ¨¡å‹ç±»å‹
            num_classes: ç±»åˆ«æ•°é‡
            output_size: è¾“å‡ºå°ºå¯¸
            pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
            background_class: æ˜¯å¦åŒ…å«èƒŒæ™¯ç±»åˆ«
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            
        Returns:
            segmentation_masks: åˆ†å‰²æ©ç  [B, H, W]
            overlay_image: å¸¦åˆ†å‰²ç»“æœå åŠ çš„å›¾åƒ [B, H, W, C]
            class_probabilities: å„ç±»åˆ«çš„æ¦‚ç‡åˆ†å¸ƒ [B, num_classes, H, W]
        """
        # ç¡®ä¿è¾“å…¥å›¾åƒä¸ºæ­£ç¡®çš„æ ¼å¼
        batch_size, height, width, channels = image_batch.shape
        
        # å¦‚æœåŒ…å«èƒŒæ™¯ç±»ï¼Œåˆ™å®é™…ç±»åˆ«æ•°+1
        actual_num_classes = num_classes + 1 if background_class else num_classes
        
        # æ¨¡æ‹Ÿè¯­ä¹‰åˆ†å‰²è¿‡ç¨‹ï¼ˆå®é™…å®ç°ä¸­è¿™é‡Œä¼šåŠ è½½æ¨¡å‹å¹¶è¿›è¡Œæ¨ç†ï¼‰
        # è¿™é‡Œä¸ºäº†æ¼”ç¤ºç›®çš„ï¼Œæˆ‘ä»¬å°†ç”Ÿæˆä¼ªåˆ†å‰²ç»“æœ
        segmentation_masks = torch.randint(0, actual_num_classes, (batch_size, output_size, output_size))
        
        # ç”Ÿæˆä¼ªæ¦‚ç‡å›¾
        probabilities = torch.rand(batch_size, actual_num_classes, output_size, output_size)
        probabilities = F.softmax(probabilities, dim=1)  # å½’ä¸€åŒ–æ¦‚ç‡
        
        # ç”Ÿæˆå¸¦åˆ†å‰²ç»“æœå åŠ çš„å›¾åƒ
        overlay_image = image_batch.clone()
        
        # å¦‚æœéœ€è¦è°ƒæ•´è¾“å‡ºå¤§å°
        if output_size != height or output_size != width:
            overlay_image = F.interpolate(
                overlay_image.permute(0, 3, 1, 2), 
                size=(output_size, output_size), 
                mode='bilinear'
            ).permute(0, 2, 3, 1)
        
        # åº”ç”¨ç½®ä¿¡åº¦é˜ˆå€¼è¿‡æ»¤ä½ç½®ä¿¡åº¦é¢„æµ‹
        max_probs, _ = torch.max(probabilities, dim=1)
        mask = max_probs > confidence_threshold
        segmentation_masks = segmentation_masks.float() * mask.float()
        
        return (
            segmentation_masks.long(),  # åˆ†å‰²æ©ç 
            overlay_image,              # å åŠ å›¾åƒ
            probabilities               # ç±»åˆ«æ¦‚ç‡
        )

    @classmethod
    def IS_CHANGED(cls, **kwargs):
        return False


class InstanceSegmentationNode:
    """
    å®ä¾‹åˆ†å‰²èŠ‚ç‚¹
    
    ä¸è¯­ä¹‰åˆ†å‰²ä¸åŒï¼Œå®ä¾‹åˆ†å‰²ä¸ä»…åŒºåˆ†ä¸åŒçš„è¯­ä¹‰ç±»åˆ«ï¼Œ
    è¿˜èƒ½åŒºåˆ†åŒä¸€ç±»åˆ«ä¸­çš„ä¸åŒä¸ªä½“ã€‚
    """
    
    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Dict[str, Any]]:
        return {
            "required": {
                "image_batch": ("IMAGE",),
                "instance_model": ([
                    "maskrcnn_resnet50_fpn",
                    "maskrcnn_resnet101_fpn",
                    "cascade_mask_rcnn"
                ], {"default": "maskrcnn_resnet50_fpn"}),
                "max_detections": ("INT", {"default": 100, "min": 1, "max": 1000, "step": 1})
            },
            "optional": {
                "score_threshold": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}),
                "nms_threshold": ("FLOAT", {"default": 0.3, "min": 0.0, "max": 1.0, "step": 0.01}),
                "pretrained": ("BOOLEAN", {"default": True})
            }
        }

    RETURN_TYPES = ("MASK", "IMAGE", "TENSOR", "STRING")
    RETURN_NAMES = ("instance_masks", "detection_boxes", "class_scores", "labels")
    FUNCTION = "detect_instances"
    CATEGORY = "ComfyNN/DeepLearning/ComputerVision"

    def detect_instances(
        self,
        image_batch: torch.Tensor,
        instance_model: str,
        max_detections: int,
        score_threshold: float = 0.5,
        nms_threshold: float = 0.3,
        pretrained: bool = True
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, List[str]]:
        """
        æ‰§è¡Œå®ä¾‹åˆ†å‰²
        
        Args:
            image_batch: è¾“å…¥å›¾åƒæ‰¹æ¬¡ [B, H, W, C]
            instance_model: å®ä¾‹åˆ†å‰²æ¨¡å‹
            max_detections: æœ€å¤§æ£€æµ‹æ•°é‡
            score_threshold: åˆ†æ•°é˜ˆå€¼
            nms_threshold: éæå¤§æŠ‘åˆ¶é˜ˆå€¼
            pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
            
        Returns:
            instance_masks: å®ä¾‹æ©ç  [B, N, H, W]
            detection_boxes: æ£€æµ‹æ¡† [B, N, 4]
            class_scores: ç±»åˆ«åˆ†æ•° [B, N, num_classes]
            labels: æ ‡ç­¾åˆ—è¡¨
        """
        batch_size, height, width, channels = image_batch.shape
        
        # ç”Ÿæˆä¼ªå®ä¾‹åˆ†å‰²ç»“æœ
        num_instances = min(max_detections, 10)  # é™åˆ¶å®ä¾‹æ•°é‡ä»¥ä¾¿æ¼”ç¤º
        
        # ç”Ÿæˆä¼ªå®ä¾‹æ©ç 
        instance_masks = torch.rand(batch_size, num_instances, height, width) > 0.5
        instance_masks = instance_masks.float()
        
        # ç”Ÿæˆä¼ªæ£€æµ‹æ¡† (x1, y1, x2, y2)
        detection_boxes = torch.rand(batch_size, num_instances, 4)
        detection_boxes[:, :, 2:] += detection_boxes[:, :, :2]  # ç¡®ä¿x2>x1, y2>y1
        detection_boxes = torch.clamp(detection_boxes, 0, 1)
        
        # ç”Ÿæˆä¼ªç±»åˆ«åˆ†æ•°
        class_scores = torch.rand(batch_size, num_instances, 10)  # å‡è®¾æœ‰10ä¸ªç±»åˆ«
        class_scores = F.softmax(class_scores, dim=-1)
        
        # ç”Ÿæˆæ ‡ç­¾
        labels = [f"instance_{i}" for i in range(num_instances)]
        
        return (
            instance_masks,
            detection_boxes,
            class_scores,
            labels
        )

    @classmethod
    def IS_CHANGED(cls, **kwargs):
        return False


# Nodeå¯¼å‡ºæ˜ å°„
NODE_CLASS_MAPPINGS = {
    "SemanticSegmentationNode": SemanticSegmentationNode,
    "InstanceSegmentationNode": InstanceSegmentationNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "SemanticSegmentationNode": "Semantic Segmentation ğŸ±",
    "InstanceSegmentationNode": "Instance Segmentation ğŸ±"
}