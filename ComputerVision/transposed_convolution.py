import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Tuple, Dict, Any

class TransposedConv2DNode:
    """
    è½¬ç½®å·ç§¯ï¼ˆåå·ç§¯ï¼‰èŠ‚ç‚¹
    
    è½¬ç½®å·ç§¯å¸¸ç”¨äºä¸Šé‡‡æ ·æ“ä½œï¼Œç‰¹åˆ«æ˜¯åœ¨è¯­ä¹‰åˆ†å‰²å’Œç”Ÿæˆæ¨¡å‹ä¸­ã€‚
    å®ƒå¯ä»¥å°†ä½åˆ†è¾¨ç‡ç‰¹å¾å›¾ä¸Šé‡‡æ ·åˆ°é«˜åˆ†è¾¨ç‡ã€‚
    """
    
    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Dict[str, Any]]:
        return {
            "required": {
                "input_tensor": ("TENSOR",),
                "in_channels": ("INT", {"default": 64, "min": 1, "max": 1024, "step": 1}),
                "out_channels": ("INT", {"default": 32, "min": 1, "max": 1024, "step": 1}),
                "kernel_size": ("INT", {"default": 4, "min": 1, "max": 15, "step": 2}),
                "stride": ("INT", {"default": 2, "min": 1, "max": 8, "step": 1}),
                "padding": ("INT", {"default": 1, "min": 0, "max": 8, "step": 1}),
            },
            "optional": {
                "output_padding": ("INT", {"default": 0, "min": 0, "max": 8, "step": 1}),
                "dilation": ("INT", {"default": 1, "min": 1, "max": 8, "step": 1}),
                "activation": (["relu", "leaky_relu", "sigmoid", "tanh", "none"], {"default": "relu"}),
                "use_bias": ("BOOLEAN", {"default": True}),
                "groups": ("INT", {"default": 1, "min": 1, "max": 128, "step": 1})
            }
        }

    RETURN_TYPES = ("TENSOR",)
    RETURN_NAMES = ("output_tensor",)
    FUNCTION = "transposed_conv2d"
    CATEGORY = "ComfyNN/DeepLearning/ComputerVision"

    def transposed_conv2d(
        self,
        input_tensor: torch.Tensor,
        in_channels: int,
        out_channels: int,
        kernel_size: int,
        stride: int = 2,
        padding: int = 1,
        output_padding: int = 0,
        dilation: int = 1,
        activation: str = "relu",
        use_bias: bool = True,
        groups: int = 1
    ) -> Tuple[torch.Tensor]:
        """
        æ‰§è¡Œ2Dè½¬ç½®å·ç§¯æ“ä½œ
        
        Args:
            input_tensor: è¾“å…¥å¼ é‡ [N, C, H, W]
            in_channels: è¾“å…¥é€šé“æ•°
            out_channels: è¾“å‡ºé€šé“æ•°
            kernel_size: å·ç§¯æ ¸å¤§å°
            stride: æ­¥é•¿
            padding: å¡«å……
            output_padding: è¾“å‡ºå¡«å……
            dilation: è†¨èƒ€ç³»æ•°
            activation: æ¿€æ´»å‡½æ•°ç±»å‹
            use_bias: æ˜¯å¦ä½¿ç”¨åç½®
            groups: åˆ†ç»„å·ç§¯ç»„æ•°
            
        Returns:
            output_tensor: è¾“å‡ºå¼ é‡ [N, out_channels, H_out, W_out]
        """
        # ç¡®ä¿è¾“å…¥å¼ é‡ç»´åº¦æ­£ç¡®
        if input_tensor.dim() != 4:
            raise ValueError(f"è¾“å…¥å¼ é‡åº”ä¸º4ç»´ [N, C, H, W]ï¼Œå½“å‰ç»´åº¦: {input_tensor.dim()}")
        
        # åˆ›å»ºè½¬ç½®å·ç§¯å±‚
        transposed_conv = nn.ConvTranspose2d(
            in_channels=in_channels,
            out_channels=out_channels,
            kernel_size=kernel_size,
            stride=stride,
            padding=padding,
            output_padding=output_padding,
            dilation=dilation,
            bias=use_bias,
            groups=groups
        )
        
        # åº”ç”¨è½¬ç½®å·ç§¯
        output_tensor = transposed_conv(input_tensor)
        
        # åº”ç”¨æ¿€æ´»å‡½æ•°
        if activation == "relu":
            output_tensor = F.relu(output_tensor)
        elif activation == "leaky_relu":
            output_tensor = F.leaky_relu(output_tensor)
        elif activation == "sigmoid":
            output_tensor = torch.sigmoid(output_tensor)
        elif activation == "tanh":
            output_tensor = torch.tanh(output_tensor)
        # "none" æƒ…å†µä¸‹ä¸åº”ç”¨æ¿€æ´»å‡½æ•°
        
        return (output_tensor,)

    @classmethod
    def IS_CHANGED(cls, **kwargs):
        return False


class MultiScaleTransposedConvNode:
    """
    å¤šå°ºåº¦è½¬ç½®å·ç§¯èŠ‚ç‚¹
    
    åŒæ—¶ä½¿ç”¨å¤šä¸ªä¸åŒå°ºåº¦çš„è½¬ç½®å·ç§¯æ ¸è¿›è¡Œä¸Šé‡‡æ ·ï¼Œ
    ç„¶åå°†ç»“æœèåˆä»¥è·å¾—æ›´ä¸°å¯Œçš„ç‰¹å¾è¡¨ç¤ºã€‚
    """
    
    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Dict[str, Any]]:
        return {
            "required": {
                "input_tensor": ("TENSOR",),
                "base_channels": ("INT", {"default": 64, "min": 1, "max": 512, "step": 1}),
                "target_channels": ("INT", {"default": 32, "min": 1, "max": 512, "step": 1}),
                "base_kernel_size": ("INT", {"default": 4, "min": 2, "max": 15, "step": 2}),
            },
            "optional": {
                "num_scales": ("INT", {"default": 3, "min": 1, "max": 5, "step": 1}),
                "stride": ("INT", {"default": 2, "min": 1, "max": 8, "step": 1}),
                "padding": ("INT", {"default": 1, "min": 0, "max": 8, "step": 1}),
                "activation": (["relu", "leaky_relu", "sigmoid", "tanh", "none"], {"default": "relu"}),
                "use_bias": ("BOOLEAN", {"default": True})
            }
        }

    RETURN_TYPES = ("TENSOR",)
    RETURN_NAMES = ("output_tensor",)
    FUNCTION = "multi_scale_transposed_conv"
    CATEGORY = "ComfyNN/DeepLearning/ComputerVision"

    def multi_scale_transposed_conv(
        self,
        input_tensor: torch.Tensor,
        base_channels: int,
        target_channels: int,
        base_kernel_size: int,
        num_scales: int = 3,
        stride: int = 2,
        padding: int = 1,
        activation: str = "relu",
        use_bias: bool = True
    ) -> Tuple[torch.Tensor]:
        """
        æ‰§è¡Œå¤šå°ºåº¦è½¬ç½®å·ç§¯æ“ä½œ
        
        Args:
            input_tensor: è¾“å…¥å¼ é‡ [N, C, H, W]
            base_channels: åŸºç¡€é€šé“æ•°
            target_channels: ç›®æ ‡é€šé“æ•°
            base_kernel_size: åŸºç¡€å·ç§¯æ ¸å¤§å°
            num_scales: å°ºåº¦æ•°é‡
            stride: æ­¥é•¿
            padding: å¡«å……
            activation: æ¿€æ´»å‡½æ•°ç±»å‹
            use_bias: æ˜¯å¦ä½¿ç”¨åç½®
            
        Returns:
            output_tensor: è¾“å‡ºå¼ é‡ [N, target_channels, H_out, W_out]
        """
        # ç¡®ä¿è¾“å…¥å¼ é‡ç»´åº¦æ­£ç¡®
        if input_tensor.dim() != 4:
            raise ValueError(f"è¾“å…¥å¼ é‡åº”ä¸º4ç»´ [N, C, H, W]ï¼Œå½“å‰ç»´åº¦: {input_tensor.dim()}")
        
        batch_size, channels, height, width = input_tensor.shape
        
        # åˆ›å»ºå¤šä¸ªä¸åŒå°ºåº¦çš„è½¬ç½®å·ç§¯å±‚
        transposed_convs = []
        for i in range(num_scales):
            kernel_size = base_kernel_size + 2 * i  # é€æ­¥å¢åŠ æ ¸å¤§å°
            out_channels = max(1, target_channels // num_scales)  # åˆ†é…è¾“å‡ºé€šé“
            
            conv = nn.ConvTranspose2d(
                in_channels=channels,
                out_channels=out_channels,
                kernel_size=kernel_size,
                stride=stride,
                padding=padding,
                bias=use_bias
            )
            transposed_convs.append(conv)
        
        # åº”ç”¨æ‰€æœ‰è½¬ç½®å·ç§¯
        outputs = []
        for conv in transposed_convs:
            out = conv(input_tensor)
            outputs.append(out)
        
        # è°ƒæ•´æ‰€æœ‰è¾“å‡ºåˆ°ç›¸åŒå°ºå¯¸ï¼ˆä½¿ç”¨æœ€å¤§çš„å°ºå¯¸ï¼‰
        max_height = max([out.shape[2] for out in outputs])
        max_width = max([out.shape[3] for out in outputs])
        
        resized_outputs = []
        for out in outputs:
            if out.shape[2] != max_height or out.shape[3] != max_width:
                out = F.interpolate(out, size=(max_height, max_width), mode='bilinear', align_corners=False)
            resized_outputs.append(out)
        
        # åˆå¹¶æ‰€æœ‰è¾“å‡º
        combined_output = torch.cat(resized_outputs, dim=1)
        
        # å¦‚æœåˆå¹¶åçš„é€šé“æ•°ä¸ç›®æ ‡é€šé“æ•°ä¸åŒ¹é…ï¼Œæ·»åŠ ä¸€ä¸ª1x1å·ç§¯è°ƒæ•´é€šé“æ•°
        if combined_output.shape[1] != target_channels:
            channel_adjust = nn.Conv2d(
                in_channels=combined_output.shape[1],
                out_channels=target_channels,
                kernel_size=1,
                bias=use_bias
            )
            combined_output = channel_adjust(combined_output)
        
        # åº”ç”¨æ¿€æ´»å‡½æ•°
        if activation == "relu":
            combined_output = F.relu(combined_output)
        elif activation == "leaky_relu":
            combined_output = F.leaky_relu(combined_output)
        elif activation == "sigmoid":
            combined_output = torch.sigmoid(combined_output)
        elif activation == "tanh":
            combined_output = torch.tanh(combined_output)
        # "none" æƒ…å†µä¸‹ä¸åº”ç”¨æ¿€æ´»å‡½æ•°
        
        return (combined_output,)

    @classmethod
    def IS_CHANGED(cls, **kwargs):
        return False


# Nodeå¯¼å‡ºæ˜ å°„
NODE_CLASS_MAPPINGS = {
    "TransposedConv2DNode": TransposedConv2DNode,
    "MultiScaleTransposedConvNode": MultiScaleTransposedConvNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "TransposedConv2DNode": "Transposed Conv 2D ğŸ±",
    "MultiScaleTransposedConvNode": "Multi-Scale Transposed Conv ğŸ±"
}